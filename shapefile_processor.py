import os
import geopandas as gpd
import json
import logging
from sqlalchemy import create_engine, text
import tempfile
import zipfile
from map_builder import process_geojson_file
from datetime import datetime
import shutil
from config import DB_URL, UPLOADS_FOLDER

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class ShapefileProcessor:
    def __init__(self, db_url=DB_URL):
        self.db_url = db_url
        self.engine = create_engine(db_url)

    def debug_table_creation(self):
        """–ú–µ—Ç–æ–¥ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã"""
        try:
            with self.engine.connect() as conn:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                result = conn.execute(text("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' AND table_name = 'russia_regions'
                    );
                """))
                exists = result.scalar()
                logger.info(f"–¢–∞–±–ª–∏—Ü–∞ russia_regions —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {exists}")
                
                if exists:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã
                    result = conn.execute(text("""
                        SELECT column_name, data_type 
                        FROM information_schema.columns 
                        WHERE table_schema = 'public' AND table_name = 'russia_regions'
                        ORDER BY ordinal_position;
                    """))
                    columns = [f"{row[0]} ({row[1]})" for row in result]
                    logger.info(f"–°—Ç—Ä—É–∫—Ç—É—Ä–∞ —Ç–∞–±–ª–∏—Ü—ã: {columns}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π
                    result = conn.execute(text("SELECT COUNT(*) FROM russia_regions;"))
                    count = result.scalar()
                    logger.info(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –≤ —Ç–∞–±–ª–∏—Ü–µ: {count}")
                
                return exists
                
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ª–∞–¥–∫–µ —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return False

    def extract_shapefile(self, file_path):
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç shapefile –∏–∑ zip –∏–ª–∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–º—É —Ñ–∞–π–ª—É"""
        if file_path.lower().endswith('.zip'):
            # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏
            temp_dir = tempfile.mkdtemp()
            logger.info(f"–†–∞—Å–ø–∞–∫–æ–≤–∫–∞ ZIP –∞—Ä—Ö–∏–≤–∞ –≤: {temp_dir}")
            
            try:
                # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –∞—Ä—Ö–∏–≤
                with zipfile.ZipFile(file_path, 'r') as zip_ref:
                    zip_ref.extractall(temp_dir)
                logger.info("ZIP –∞—Ä—Ö–∏–≤ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω")
                
                # –ò—â–µ–º .shp —Ñ–∞–π–ª –≤ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
                shp_files = []
                for root, dirs, files in os.walk(temp_dir):
                    for file in files:
                        if file.lower().endswith('.shp'):
                            shp_files.append(os.path.join(root, file))
                
                if not shp_files:
                    logger.error("–í –∞—Ä—Ö–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω .shp —Ñ–∞–π–ª")
                    raise ValueError("–í –∞—Ä—Ö–∏–≤–µ –Ω–µ –Ω–∞–π–¥–µ–Ω .shp —Ñ–∞–π–ª")
                
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π .shp —Ñ–∞–π–ª
                shp_path = shp_files[0]
                logger.info(f"–ù–∞–π–¥–µ–Ω shapefile: {shp_path}")
                
                return shp_path
                    
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–∏ ZIP –∞—Ä—Ö–∏–≤–∞: {e}")
                # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
                shutil.rmtree(temp_dir, ignore_errors=True)
                raise e
        else:
            # –ï—Å–ª–∏ —ç—Ç–æ –Ω–µ ZIP, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Ç—å –∫–∞–∫ –µ—Å—Ç—å
            return file_path
    
    def shapefile_to_geojson(self, shapefile_path):
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç shapefile –≤ GeoJSON"""
        # –ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å —Ä–∞–∑–Ω—ã–º–∏ –∫–æ–¥–∏—Ä–æ–≤–∫–∞–º–∏
        encodings = ['utf-8', 'cp1251', 'iso-8859-5', 'koi8-r']
        gdf = None
        used_encoding = 'utf-8'
        region_col = 'region'

        for enc in encodings:
            try:
                logger.info(f"–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π: {enc}")
                gdf = gpd.read_file(shapefile_path, encoding=enc)
                
                # –ò—â–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏ —Ä–µ–≥–∏–æ–Ω–æ–≤
                for col in gdf.select_dtypes(include='object').columns:
                    if not gdf[col].dropna().empty:
                        sample = gdf[col].dropna().astype(str).iloc[0]
                        if any(c in sample.lower() for c in '–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è'):
                            region_col = col
                            used_encoding = enc
                            logger.info(f"–ù–∞–π–¥–µ–Ω —Å—Ç–æ–ª–±–µ—Ü —Å –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏: '{region_col}' (–∫–æ–¥–∏—Ä–æ–≤–∫–∞: {enc})")
                            break
                else:
                    continue
                break
            except Exception as e:
                logger.warning(f"–ö–æ–¥–∏—Ä–æ–≤–∫–∞ {enc} –Ω–µ –ø–æ–¥–æ—à–ª–∞: {e}")
                continue
        else:
            # Fallback: –±–µ–∑ —É–∫–∞–∑–∞–Ω–∏—è –∫–æ–¥–∏—Ä–æ–≤–∫–∏
            logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–æ–¥–∏—Ä–æ–≤–∫–∏")
            gdf = gpd.read_file(shapefile_path)
            # –í—ã–±–∏—Ä–∞–µ–º –ø–µ—Ä–≤—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –∫–∞–∫ –Ω–∞–∑–≤–∞–Ω–∏–µ
            text_cols = gdf.select_dtypes(include='object').columns.tolist()
            region_col = text_cols[0] if text_cols else 'region_name'

        # –ü—Ä–∏–≤–æ–¥–∏–º CRS –∫ WGS84 (EPSG:4326)
        if gdf.crs is None:
            gdf = gdf.set_crs('EPSG:4326')
            logger.info("–£—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω CRS: EPSG:4326")
        elif gdf.crs.to_epsg() != 4326:
            gdf = gdf.to_crs('EPSG:4326')
            logger.info("–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω –≤ CRS: EPSG:4326")
        else:
            logger.info("CRS —É–∂–µ EPSG:4326")

        # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –ø–æ–ª—è
        gdf = gdf[[region_col, 'geometry']].copy()
        gdf.rename(columns={region_col: 'region'}, inplace=True)

        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        gdf = self._fix_encoding(gdf, used_encoding)

        # –°–æ–∑–¥–∞–µ–º GeoJSON —Å—Ç—Ä—É–∫—Ç—É—Ä—É
        geojson_data = {
            "type": "FeatureCollection",
            "features": []
        }

        for idx, row in gdf.iterrows():
            # –ü—Ä–∞–≤–∏–ª—å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≥–µ–æ–º–µ—Ç—Ä–∏–∏ –≤ GeoJSON
            if hasattr(row.geometry, '__geo_interface__'):
                geometry_json = row.geometry.__geo_interface__
            else:
                try:
                    from shapely.geometry import mapping
                    geometry_json = mapping(row.geometry)
                except:
                    geometry_json = {
                        "type": "GeometryCollection",
                        "geometries": []
                    }

            feature = {
                "type": "Feature",
                "properties": {
                    "region": row['region']
                },
                "geometry": geometry_json
            }
            geojson_data["features"].append(feature)

        logger.info(f"–°–æ–∑–¥–∞–Ω GeoJSON —Å {len(gdf)} —Ä–µ–≥–∏–æ–Ω–∞–º–∏")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã –Ω–∞–∑–≤–∞–Ω–∏–π
        if len(gdf) > 0:
            logger.info("–ü—Ä–∏–º–µ—Ä—ã —Ä–µ–≥–∏–æ–Ω–æ–≤:")
            for i, region in enumerate(gdf['region'].head(5), 1):
                logger.info(f"   {i}. {region}")
        
        return geojson_data, len(gdf)

    def _fix_encoding(self, gdf, original_encoding):
        """–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π"""
        sample_text = gdf['region'].iloc[0] if len(gdf) > 0 else ""
        
        # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –∫–æ–¥–∏—Ä–æ–≤–∫–∞
        if '–†' in str(sample_text) and '–°' in str(sample_text):
            logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —Å –∫–æ–¥–∏—Ä–æ–≤–∫–æ–π, –∏—Å–ø—Ä–∞–≤–ª—è–µ–º...")
            
            try:
                fixed_regions = []
                for region in gdf['region']:
                    if region and isinstance(region, str):
                        try:
                            fixed = region.encode('windows-1251').decode('utf-8')
                            fixed_regions.append(fixed)
                        except:
                            fixed_regions.append(region)
                    else:
                        fixed_regions.append(region)
                
                gdf['region'] = fixed_regions
                logger.info("–ö–æ–¥–∏—Ä–æ–≤–∫–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞")
                
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∏—Å–ø—Ä–∞–≤–∏—Ç—å –∫–æ–¥–∏—Ä–æ–≤–∫—É: {e}")
        
        return gdf

    def create_table_if_not_exists(self):
        """–°–æ–∑–¥–∞–µ—Ç —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ –æ–Ω–∞ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"""
        try:
            with self.engine.connect() as conn:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
                result = conn.execute(text("""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' AND table_name = 'russia_regions'
                    );
                """))
                table_exists = result.scalar()
                
                if not table_exists:
                    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã russia_regions...")
                    conn.execute(text("""
                        CREATE TABLE russia_regions (
                            id SERIAL PRIMARY KEY,
                            region VARCHAR(200) NOT NULL,
                            area_sq_km NUMERIC(12, 2),
                            geometry GEOMETRY(Geometry, 4326),
                            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                        );
                    """))
                    
                    # –°–æ–∑–¥–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã
                    conn.execute(text("""
                        CREATE INDEX idx_russia_regions_geom 
                        ON russia_regions USING GIST (geometry);
                        
                        CREATE INDEX idx_russia_regions_name 
                        ON russia_regions (region);
                    """))
                    conn.commit()
                    logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ russia_regions —Å–æ–∑–¥–∞–Ω–∞")
                    return True
                else:
                    logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ russia_regions —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç")
                    return True
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã: {e}")
            return False

    def load_to_database(self, geojson_data):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö PostgreSQL —Å PostGIS"""
        try:
            # –°–Ω–∞—á–∞–ª–∞ –æ—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
            logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π...")
            table_exists_before = self.debug_table_creation()
            
            # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            creation_success = self.create_table_if_not_exists()
            if not creation_success:
                logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è
            logger.info("üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–∞–±–ª–∏—Ü—ã...")
            table_exists_after = self.debug_table_creation()
            
            if not table_exists_after:
                logger.error("‚ùå –¢–∞–±–ª–∏—Ü–∞ –≤—Å–µ –µ—â–µ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ø–æ—Å–ª–µ –ø–æ–ø—ã—Ç–∫–∏ —Å–æ–∑–¥–∞–Ω–∏—è")
                return False
            
            # –û—á–∏—â–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –ø–µ—Ä–µ–¥ –∑–∞–≥—Ä—É–∑–∫–æ–π
            with self.engine.connect() as conn:
                conn.execute(text("TRUNCATE TABLE russia_regions RESTART IDENTITY;"))
                conn.commit()
                logger.info("‚úÖ –¢–∞–±–ª–∏—Ü–∞ –æ—á–∏—â–µ–Ω–∞")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É
            inserted_count = 0
            with self.engine.connect() as conn:
                for feature in geojson_data['features']:
                    region_name = feature['properties']['region']
                    geometry_json = json.dumps(feature['geometry'])
                    
                    logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–≥–∏–æ–Ω–∞: {region_name}")
                    
                    try:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ST_GeomFromGeoJSON –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –≥–µ–æ–º–µ—Ç—Ä–∏–∏
                        conn.execute(text("""
                            INSERT INTO russia_regions (region, area_sq_km, geometry)
                            VALUES (
                                :region_name,
                                ST_Area(ST_GeomFromGeoJSON(:geometry)::geography) / 1000000.0,
                                ST_GeomFromGeoJSON(:geometry)
                            )
                        """), {
                            'region_name': region_name,
                            'geometry': geometry_json
                        })
                        inserted_count += 1
                    except Exception as e:
                        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤—Å—Ç–∞–≤–∫–∏ —Ä–µ–≥–∏–æ–Ω–∞ {region_name}: {e}")
                        continue
                
                # –û–∫—Ä—É–≥–ª—è–µ–º –ø–ª–æ—â–∞–¥–∏
                try:
                    conn.execute(text("""
                        UPDATE russia_regions 
                        SET area_sq_km = ROUND(area_sq_km, 2)
                    """))
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –æ–∫—Ä—É–≥–ª–∏—Ç—å –ø–ª–æ—â–∞–¥–∏: {e}")
                
                conn.commit()
            
            # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
            logger.info("üîç –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö...")
            self.debug_table_creation()
            
            logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –±–∞–∑—É: {inserted_count} —Ä–µ–≥–∏–æ–Ω–æ–≤")
            return inserted_count > 0
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤ –±–∞–∑—É: {e}")
            import traceback
            logger.error(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {traceback.format_exc()}")
            return False


def save_geojson_to_uploads(geojson_data):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç GeoJSON –¥–∞–Ω–Ω—ã–µ –≤ –ø–∞–ø–∫—É uploads –∫–∞–∫ russia_regions.geojson (–ü–ï–†–ï–ó–ê–ü–ò–°–´–í–ê–ï–¢!)"""
    try:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É uploads –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(UPLOADS_FOLDER, exist_ok=True)
        
        # –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        geojson_path = os.path.join(UPLOADS_FOLDER, "russia_regions.geojson")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º GeoJSON (–ü–ï–†–ï–ó–ê–ü–ò–°–´–í–ê–ï–ú!)
        with open(geojson_path, 'w', encoding='utf-8') as f:
            json.dump(geojson_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"‚úÖ GeoJSON —Å–æ—Ö—Ä–∞–Ω–µ–Ω/–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω –∫–∞–∫: {geojson_path}")
        return geojson_path
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è GeoJSON: {e}")
        return None


def process_shapefile(file_path, original_filename):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ shapefile"""
    temp_dir = None
    try:
        processor = ShapefileProcessor()
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º shapefile –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        shapefile_path = processor.extract_shapefile(file_path)
        logger.info(f"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è shapefile: {os.path.basename(shapefile_path)}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ GeoJSON
        geojson_data, regions_count = processor.shapefile_to_geojson(shapefile_path)
        
        if regions_count == 0:
            return {
                "success": False,
                "error": "Shapefile –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–∞–Ω–Ω—ã—Ö"
            }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º GeoJSON –≤ –ø–∞–ø–∫—É uploads
        geojson_path = save_geojson_to_uploads(geojson_data)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        db_success = processor.load_to_database(geojson_data)
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ–º
        plotly_data = process_geojson_file(geojson_data, force_refresh=True)
        
        return {
            "success": True,
            "plotly_data": plotly_data,
            "regions_count": regions_count,
            "database_updated": db_success,
            "geojson_saved": geojson_path is not None
        }
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ shapefile: {e}")
        return {
            "success": False,
            "error": str(e)
        }
    finally:
        # –û—á–∏—â–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
        if temp_dir and os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)