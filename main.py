# uvicorn main:app --reload --host 0.0.0.0 --port 8000
 
# main.py
from sqlalchemy import create_engine, text
from fastapi import FastAPI, File, UploadFile, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import HTMLResponse, JSONResponse
import os
import json
from datetime import datetime
import uuid
import shutil
import pandas as pd
from map_builder import process_geojson_file, get_last_map
from shapefile_processor import process_shapefile
from flight_data_processor import process_flight_data_excel
from metrics_calculator import BasicMetricsCalculator, calculate_metrics
import traceback
from sqlalchemy import text
from overview_metrics import get_overview_metrics
import tempfile
from shapefile_processor import ShapefileProcessor, process_shapefile, save_geojson_to_uploads

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–∑ config
from config import DB_URL, UPLOADS_FOLDER

app = FastAPI()

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
UPLOAD_DIR = os.path.join(BASE_DIR, UPLOADS_FOLDER)
SHAPEFILE_DIR = os.path.join(BASE_DIR, "shapefile_uploads")
FLIGHT_DATA_DIR = os.path.join(BASE_DIR, "flight_data_uploads")

# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –∑–∞–≥—Ä—É–∑–æ–∫, –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç
os.makedirs(UPLOAD_DIR, exist_ok=True)
os.makedirs(SHAPEFILE_DIR, exist_ok=True)
os.makedirs(FLIGHT_DATA_DIR, exist_ok=True)

app.mount("/static", StaticFiles(directory=os.path.join(BASE_DIR, "static")), name="static")

@app.get("/", response_class=HTMLResponse)
async def read_root():
    with open(os.path.join(BASE_DIR, "templates", "index.html"), "r", encoding="utf-8") as f:
        return HTMLResponse(f.read())
    

@app.get("/metrics/all_regions")
async def get_all_regions_metrics():
    """–ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è –æ–±—â–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏"""
    try:
        calculator = BasicMetricsCalculator(DB_URL)
        metrics = calculator.get_all_regions_metrics()
        return JSONResponse(metrics)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤: {str(e)}")
        return JSONResponse({"error": str(e)}, status_code=500)

@app.get("/last_map")
async def get_last_processed_map():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥–Ω—é—é –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—É—é –∫–∞—Ä—Ç—É"""
    try:
        last_map = get_last_map()
        if last_map:
            return JSONResponse(last_map)
        else:
            return JSONResponse({"error": "–ù–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã—Ö –∫–∞—Ä—Ç"}, status_code=404)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–∞—Ä—Ç—ã: {str(e)}")

@app.post("/process")
async def process_uploaded_file(file: UploadFile = File(...)):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã (GeoJSON –∏–ª–∏ Shapefile)"""
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
    filename_lower = file.filename.lower()
    
    if filename_lower.endswith((".json", ".geojson")):
        return await process_geojson_file_handler(file)
    elif filename_lower.endswith((".shp", ".shx", ".dbf", ".prj", ".zip")):
        return await process_shapefile_handler(file)
    else:
        raise HTTPException(
            status_code=400, 
            detail="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ .json, .geojson, .shp, .shx, .dbf, .prj –∏ .zip —Ñ–∞–π–ª—ã"
        )

@app.post("/process_flights")
async def process_flight_data_file(file: UploadFile = File(...)):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–æ–ª–µ—Ç–∞—Ö (XLSX)"""
    
    if not file.filename.lower().endswith(('.xlsx', '.xls')):
        raise HTTPException(
            status_code=400, 
            detail="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ .xlsx –∏ .xls —Ñ–∞–π–ª—ã"
        )
    
    result = await process_flight_data_handler(file)
    
    if result.get("success"):
        try:
            metrics_result = calculate_metrics()
            if metrics_result["success"]:
                print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –¥–ª—è {metrics_result['regions_count']} —Ä–µ–≥–∏–æ–Ω–æ–≤")
            else:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å—Å—á–∏—Ç–∞—Ç—å –º–µ—Ç—Ä–∏–∫–∏: {metrics_result.get('error')}")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–º —Ä–∞—Å—á–µ—Ç–µ –º–µ—Ç—Ä–∏–∫: {e}")
    
    return JSONResponse(result)

@app.post("/calculate_metrics")
async def calculate_basic_metrics():
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ä–∞—Å—á–µ—Ç –±–∞–∑–æ–≤—ã—Ö –º–µ—Ç—Ä–∏–∫"""
    try:
        print("üöÄ –ó–∞–ø—É—Å–∫ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫...")
        result = calculate_metrics(DB_URL)  # –Ø–≤–Ω–æ –ø–µ—Ä–µ–¥–∞–µ–º DB_URL
        
        if result["success"]:
            print(f"‚úÖ –ú–µ—Ç—Ä–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –¥–ª—è {result['regions_count']} —Ä–µ–≥–∏–æ–Ω–æ–≤")
            return JSONResponse({
                "success": True,
                "message": f"–ú–µ—Ç—Ä–∏–∫–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã –¥–ª—è {result['regions_count']} —Ä–µ–≥–∏–æ–Ω–æ–≤",
                "regions_count": result['regions_count']
            })
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫: {result.get('error')}")
            return JSONResponse({
                "success": False,
                "error": result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"),
                "message": "–ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –±—ã–ª–∏ —Ä–∞—Å—Å—á–∏—Ç–∞–Ω—ã"
            })
    except Exception as e:
        error_msg = f"üí• –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫: {str(e)}"
        print(error_msg)
        return JSONResponse({
            "success": False,
            "error": str(e),
            "message": "–û—à–∏–±–∫–∞ —Ä–∞—Å—á–µ—Ç–∞ –º–µ—Ç—Ä–∏–∫"
        })

@app.get("/metrics/region/{region_id}")
async def get_region_metrics(region_id: int):
    """–ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–∞"""
    try:
        calculator = BasicMetricsCalculator(DB_URL)
        
        metrics = calculator.get_region_metrics(region_id)
        if not metrics:
            raise HTTPException(status_code=404, detail="–ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–µ–≥–∏–æ–Ω–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
        return JSONResponse({
            "region_id": metrics[1],
            "region_name": metrics[2],
            "flight_count": metrics[3],
            "avg_duration_minutes": float(metrics[4]) if metrics[4] else 0,
            "total_duration_minutes": metrics[5],
            "peak_load_per_hour": metrics[6],
            "avg_daily_flights": float(metrics[7]) if metrics[7] else 0,
            "median_daily_flights": float(metrics[8]) if metrics[8] else 0,
            "flight_density": float(metrics[9]) if metrics[9] else 0,
            "time_distribution": {
                "morning": metrics[10],
                "day": metrics[11],
                "evening": metrics[12],
                "night": metrics[13]
            },
            "last_calculated": metrics[14].isoformat() if metrics[14] else None
        })
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫: {str(e)}")

@app.get("/metrics/overall")
async def get_overall_metrics():
    try:
        metrics = get_overview_metrics()
        return JSONResponse(metrics)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –æ–±—â–µ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
        return JSONResponse({
            "total_flights": 0,
            "avg_duration": 0.0,
            "total_duration": 0,
            "regions_with_flights": 0,
            "top_regions": []
        })

@app.get("/metrics/regions")
async def get_all_regions_metrics():
    """–ü–æ–ª—É—á–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤"""
    try:
        calculator = BasicMetricsCalculator(DB_URL)
        
        metrics = calculator.get_all_regions_metrics()
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        if not metrics:
            return JSONResponse([])
        
        return JSONResponse(metrics)
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫ —Ä–µ–≥–∏–æ–Ω–æ–≤: {str(e)}")
        return JSONResponse({"error": str(e)}, status_code=500)
    
@app.get("/debug/regions")
async def debug_regions():
    """–û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ä–µ–≥–∏–æ–Ω–∞—Ö"""
    try:
        calculator = BasicMetricsCalculator(DB_URL)
        
        with calculator.engine.connect() as conn:
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ä–µ–≥–∏–æ–Ω—ã –∏–∑ –±–∞–∑—ã
            result = conn.execute(text("SELECT id, region FROM russia_regions ORDER BY id"))
            db_regions = [{"id": row[0], "name": row[1]} for row in result]
            
            return JSONResponse({
                "database_regions": db_regions,
                "total_regions": len(db_regions)
            })
    except Exception as e:
        return JSONResponse({"error": str(e)})
    

@app.get("/find_region_by_name")
async def find_region_by_name(region_name: str):
    """–ù–∞—Ö–æ–¥–∏—Ç ID —Ä–µ–≥–∏–æ–Ω–∞ –ø–æ –∏–º–µ–Ω–∏"""
    try:
        calculator = BasicMetricsCalculator(DB_URL)
        
        with calculator.engine.connect() as conn:
            result = conn.execute(
                text("SELECT id FROM russia_regions WHERE LOWER(region) = LOWER(:region_name)"),
                {"region_name": region_name}
            )
            region = result.fetchone()
            
            if region:
                return JSONResponse({"region_id": region[0], "found": True})
            else:
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                result = conn.execute(
                    text("SELECT id, region FROM russia_regions WHERE LOWER(region) LIKE LOWER(:pattern)"),
                    {"pattern": f"%{region_name}%"}
                )
                partial_match = result.fetchone()
                
                if partial_match:
                    return JSONResponse({
                        "region_id": partial_match[0], 
                        "found": True,
                        "actual_name": partial_match[1],
                        "note": "partial_match"
                    })
                else:
                    return JSONResponse({"found": False})
                    
    except Exception as e:
        return JSONResponse({"error": str(e), "found": False})

async def process_geojson_file_handler(file: UploadFile):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ GeoJSON —Ñ–∞–π–ª–æ–≤"""
    # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ russia_regions.geojson (–ü–ï–†–ï–ó–ê–ü–ò–°–´–í–ê–ï–ú!)
    file_path = os.path.join(UPLOAD_DIR, "russia_regions.geojson")

    try:
        # –ß–∏—Ç–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª (–ü–ï–†–ï–ó–ê–ü–ò–°–´–í–ê–ï–ú!)
        content = await file.read()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –Ω–∞ –¥–∏—Å–∫ (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
        with open(file_path, "wb") as f:
            f.write(content)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–æ—á–∏—Ç–∞—Ç—å –∫–∞–∫ JSON –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏
        try:
            input_data = json.loads(content.decode("utf-8"))
        except json.JSONDecodeError as e:
            raise HTTPException(status_code=400, detail=f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON —Ñ–∞–π–ª: {str(e)}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ FeatureCollection
        if not isinstance(input_data, dict) or input_data.get("type") != "FeatureCollection":
            raise HTTPException(status_code=400, detail="–û–∂–∏–¥–∞–µ—Ç—Å—è GeoJSON FeatureCollection")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ features
        if 'features' not in input_data or not input_data['features']:
            raise HTTPException(status_code=400, detail="GeoJSON –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç features")

        # –õ–æ–≥–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∂–∞–µ–º–æ–º —Ñ–∞–π–ª–µ
        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ GeoJSON —Ñ–∞–π–ª–∞: {file.filename}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ features: {len(input_data['features'])}")
        print(f"–§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω –∫–∞–∫: {file_path}")
        
        # üî• –í–ê–ñ–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –ó–∞–≥—Ä—É–∂–∞–µ–º GeoJSON –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö
        print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ GeoJSON –¥–∞–Ω–Ω—ã—Ö –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö...")
        processor = ShapefileProcessor()
        
        # –°–æ–∑–¥–∞–µ–º —Ç–∞–±–ª–∏—Ü—É –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        table_created = processor.create_table_if_not_exists()
        if not table_created:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É russia_regions")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É
        db_success = processor.load_to_database(input_data)
        
        if db_success:
            print(f"‚úÖ GeoJSON –¥–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö")
        else:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å GeoJSON –¥–∞–Ω–Ω—ã–µ –≤ –±–∞–∑—É")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª —á–µ—Ä–µ–∑ —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ map_builder —Å –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ú –û–ë–ù–û–í–õ–ï–ù–ò–ï–ú
        plotly_data = process_geojson_file(input_data, force_refresh=True)
        
        return JSONResponse({
            **plotly_data,
            "file_info": {
                "original_filename": file.filename,
                "saved_as": "russia_regions.geojson",
                "file_type": "geojson",
                "regions_count": len(input_data['features']),
                "database_updated": db_success,  # üî• –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∑–∞–≥—Ä—É–∑–∫–µ –≤ –ë–î
                "upload_time": datetime.now().isoformat()
            }
        })
        
    except HTTPException:
        raise
    except Exception as e:
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        if os.path.exists(file_path):
            os.remove(file_path)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—É—é –æ—à–∏–±–∫—É –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        error_details = traceback.format_exc()
        print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ GeoJSON —Ñ–∞–π–ª–∞: {str(e)}")
        print(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {error_details}")
        
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞: {str(e)}")

async def process_shapefile_handler(file: UploadFile):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ Shapefile —Ñ–∞–π–ª–æ–≤ - –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
    # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    temp_dir = tempfile.mkdtemp()
    
    try:
        # –ß–∏—Ç–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª –≤–æ –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É
        content = await file.read()
        file_path = os.path.join(temp_dir, file.filename)
        
        with open(file_path, "wb") as f:
            f.write(content)

        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ Shapefile –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞: {file.filename}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª
        if file.filename.lower().endswith('.zip'):
            result = process_shapefile(file_path, file.filename)
        else:
            # –î–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏—â–µ–º .shp —Ñ–∞–π–ª
            shp_file = None
            for file_in_dir in os.listdir(temp_dir):
                if file_in_dir.lower().endswith('.shp'):
                    shp_file = os.path.join(temp_dir, file_in_dir)
                    break
            
            if not shp_file:
                return JSONResponse({
                    "status": "waiting_for_components",
                    "message": "–ó–∞–≥—Ä—É–∂–µ–Ω—ã –Ω–µ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã shapefile"
                })
            
            result = process_shapefile(shp_file, file.filename)
        
        if result.get("success"):
            return JSONResponse({
                **result["plotly_data"],
                "file_info": {
                    "original_filename": file.filename,
                    "file_type": "shapefile",
                    "regions_count": result.get("regions_count", 0),
                    "database_updated": result.get("database_updated", False),
                    "upload_time": datetime.now().isoformat()
                }
            })
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞"))
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ shapefile: {str(e)}")
    finally:
        # –í—Å–µ–≥–¥–∞ —É–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –ø–∞–ø–∫—É –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir, ignore_errors=True)

async def process_zip_shapefile(zip_path: str, session_dir: str, original_filename: str):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç ZIP –∞—Ä—Ö–∏–≤ —Å shapefile"""
    try:
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º shapefile —á–µ—Ä–µ–∑ process_shapefile
        result = process_shapefile(zip_path, original_filename)
        
        if result.get("success"):
            return JSONResponse({
                **result["plotly_data"],
                "file_info": {
                    "original_filename": original_filename,
                    "file_type": "shapefile_zip",
                    "regions_count": result.get("regions_count", 0),
                    "database_updated": result.get("database_updated", False),
                    "upload_time": datetime.now().isoformat()
                }
            })
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ shapefile"))
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ ZIP –∞—Ä—Ö–∏–≤–∞: {str(e)}")

async def process_single_shapefile_component(file_path: str, session_dir: str, original_filename: str):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç shapefile"""
    try:
        # –î–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ shapefile, –º—ã –æ–∂–∏–¥–∞–µ–º, —á—Ç–æ –≤—Å–µ —Ñ–∞–π–ª—ã –±—É–¥—É—Ç –∑–∞–≥—Ä—É–∂–µ–Ω—ã
        # –≤ –æ–¥–Ω—É —Å–µ—Å—Å–∏–æ–Ω–Ω—É—é –ø–∞–ø–∫—É. –ò—â–µ–º .shp —Ñ–∞–π–ª –≤ —ç—Ç–æ–π –ø–∞–ø–∫–µ.
        shp_file = None
        for file in os.listdir(session_dir):
            if file.lower().endswith('.shp'):
                shp_file = os.path.join(session_dir, file)
                break
        
        if not shp_file:
            # –ï—Å–ª–∏ .shp —Ñ–∞–π–ª –µ—â–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω, —Å–æ–æ–±—â–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            current_files = [f for f in os.listdir(session_dir)]
            return JSONResponse({
                "status": "waiting_for_components",
                "message": "–ó–∞–≥—Ä—É–∂–µ–Ω—ã –Ω–µ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã shapefile",
                "current_files": current_files,
                "required_files": [".shp", ".shx", ".dbf", ".prj"]
            })
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º shapefile
        result = process_shapefile(shp_file, original_filename)
        
        if result.get("success"):
            return JSONResponse({
                **result["plotly_data"],
                "file_info": {
                    "original_filename": original_filename,
                    "file_type": "shapefile",
                    "regions_count": result.get("regions_count", 0),
                    "database_updated": result.get("database_updated", False),
                    "upload_time": datetime.now().isoformat()
                }
            })
        else:
            raise HTTPException(status_code=500, detail=result.get("error", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ shapefile"))
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ shapefile: {str(e)}")

async def process_flight_data_handler(file: UploadFile):
    """–û–±—Ä–∞–±–æ—Ç—á–∏–∫ —Ñ–∞–π–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–æ–ª–µ—Ç–∞—Ö - –≤—Å–µ–≥–¥–∞ –ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª"""
    # –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∫–∞–∫ flights_data.xlsx (–ü–ï–†–ï–ó–ê–ü–ò–°–´–í–ê–ï–ú!)
    file_extension = os.path.splitext(file.filename)[1]
    file_path = os.path.join(FLIGHT_DATA_DIR, f"flights_data{file_extension}")

    try:
        # –ß–∏—Ç–∞–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∞–π–ª (–ü–ï–†–ï–ó–ê–ü–ò–°–´–í–ê–ï–ú!)
        content = await file.read()
        
        with open(file_path, "wb") as f:
            f.write(content)

        print(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–æ–ª–µ—Ç–∞—Ö: {file.filename}")
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–ª–µ—Ç–∞—Ö
        result = process_flight_data_excel(file_path, file.filename)
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
        if os.path.exists(file_path):
            os.remove(file_path)
        
        error_details = traceback.format_exc()
        print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–æ–ª–µ—Ç–∞—Ö: {str(e)}")
        print(f"–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏: {error_details}")
        
        return {
            "success": False,
            "error": f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –ø–æ–ª–µ—Ç–∞—Ö: {str(e)}"
        }
    
async def save_geojson_to_database(geojson_data):
    engine = create_engine(DB_URL)
    with engine.connect() as conn:
        # –°–æ–∑–¥–∞—ë–º —Ç–∞–±–ª–∏—Ü—É, –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS russia_regions (
                id SERIAL PRIMARY KEY,
                region VARCHAR(200) NOT NULL,
                area_sq_km NUMERIC(12, 2),
                geometry GEOMETRY(Geometry, 4326)
            );
        """))
        conn.execute(text("TRUNCATE TABLE russia_regions RESTART IDENTITY;"))
        conn.commit()

        # –í—Å—Ç–∞–≤–ª—è–µ–º —Ä–µ–≥–∏–æ–Ω—ã
        for feature in geojson_data['features']:
            region_name = feature['properties'].get('region', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–≥–∏–æ–Ω')
            geometry_json = json.dumps(feature['geometry'])
            conn.execute(text("""
                INSERT INTO russia_regions (region, area_sq_km, geometry)
                VALUES (
                    :region_name,
                    ST_Area(ST_GeomFromGeoJSON(:geometry)::geography) / 1000000.0,
                    ST_GeomFromGeoJSON(:geometry)
                )
            """), {
                'region_name': region_name,
                'geometry': geometry_json
            })
        conn.execute(text("UPDATE russia_regions SET area_sq_km = ROUND(area_sq_km, 2)"))
        conn.commit()
    print("‚úÖ –¢–∞–±–ª–∏—Ü–∞ russia_regions –æ–±–Ω–æ–≤–ª–µ–Ω–∞ –∏–∑ GeoJSON")